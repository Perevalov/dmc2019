{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA,TruncatedSVD,FactorAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from utils.ScoreFunction import score_function, profit_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "from utils.paramsearch import paramsearch\n",
    "from itertools import product,chain\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\",sep='|')\n",
    "test = pd.read_csv(\"../data/test.csv\",sep='|')\n",
    "X = data.drop([\"fraud\"],axis=1)\n",
    "y = data[\"fraud\"]\n",
    "\n",
    "X['totalScanned'] = X['scannedLineItemsPerSecond']*X['totalScanTimeInSeconds']\n",
    "X['avgTimePerScan'] = 1/X['scannedLineItemsPerSecond']\n",
    "X['avgValuePerScan'] = X['avgTimePerScan']*X['valuePerSecond']\n",
    "X['withoutRegisPerPosition'] = X['scansWithoutRegistration']*X['totalScanned']\n",
    "X['quantityModsPerPosition'] = X['quantityModifications']/X['totalScanned']\n",
    "\n",
    "X['grandTotalCat'] = pd.cut(X['grandTotal'], 10,labels =[1,2,3,4,5,6,7,8,9,10])\n",
    "X['totalScanTimeInSecondsCat'] = pd.cut(X['totalScanTimeInSeconds'], 2,labels =[1,2])\n",
    "X['lineItemVoidsPerPositionCat'] = pd.cut(X['lineItemVoidsPerPosition'], 10,labels =[1,2,3,4,5,6,7,8,9,10])\n",
    "X['avgTimePerScan'] = pd.cut(X['avgTimePerScan'], 4,labels =[1,2,3,4])\n",
    "for column in X.columns:\n",
    "    X[column] = X[column].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=8)\n",
    "pca.fit(data.drop([\"fraud\"],axis=1).append(test, ignore_index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ = pca.transform(data.drop([\"fraud\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = np.concatenate((X,pca_),axis=1)\n",
    "y = np.array(y)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvaltest_xg(params, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    accuracy, score, f1 = [], [], []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = np.array(clf.predict(X_test))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        score.append(score_function(tp,fp,fn,tn))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(score)\n",
    "\n",
    "def xgboost_param_tune(params, X, y ,n_splits=5):\n",
    "    ps = paramsearch(params_xg)\n",
    "    for prms in chain(ps.grid_search(['n_estimators','learning_rate']),\n",
    "                      ps.grid_search(['max_depth','min_child_weight'])):\n",
    "        res = crossvaltest_xg(prms,X, y,n_splits)\n",
    "        ps.register_result(res,prms)\n",
    "    return ps.bestparam(), ps.bestscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvaltest_cat(params, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    accuracy, score, f1 = [], [], []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        clf = CatBoostClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = np.array(clf.predict(X_test))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        score.append(score_function(tp,fp,fn,tn))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(score)\n",
    "\n",
    "def cat_param_tune(params, X, y ,n_splits=5):\n",
    "    ps = paramsearch(params)\n",
    "    for prms in chain(ps.grid_search(['border_count']),\n",
    "                      ps.grid_search(['l2_leaf_reg']),\n",
    "                      ps.grid_search(['iterations','learning_rate']),\n",
    "                      ps.grid_search(['depth'])):\n",
    "        res = crossvaltest_cat(prms,X, y,n_splits)\n",
    "        ps.register_result(res,prms)\n",
    "    return ps.bestparam(), ps.bestscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA_BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvaltest_ada(params, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    accuracy, score, f1 = [], [], []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        clf = AdaBoostClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = np.array(clf.predict(X_test))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        score.append(score_function(tp,fp,fn,tn))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(score)\n",
    "\n",
    "def ada_param_tune(params, X, y ,n_splits=5):\n",
    "    ps = paramsearch(params)\n",
    "    for prms in chain(ps.grid_search(['n_estimators', 'learning_rate', 'algorithm'])):\n",
    "        res = crossvaltest_ada(prms,X, y,n_splits)\n",
    "        ps.register_result(res,prms)\n",
    "    return ps.bestparam(), ps.bestscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvaltest_lgb(params, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    accuracy, score, f1 = [], [], []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        clf = lgb.LGBMClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = np.array(clf.predict(X_test))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        score.append(score_function(tp,fp,fn,tn))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(score)\n",
    "\n",
    "def lgb_param_tune(params, X, y ,n_splits=5):\n",
    "    ps = paramsearch(params)\n",
    "    for prms in chain(ps.grid_search(['num_iterations', 'learning_rate']),\n",
    "                      ps.grid_search(['max_depth', 'num_leaves']),\n",
    "                      ps.grid_search(['boosting'])):\n",
    "        res = crossvaltest_lgb(prms,X, y,n_splits)\n",
    "        ps.register_result(res,prms)\n",
    "    return ps.bestparam(), ps.bestscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC_REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvaltest_log_reg(params, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    accuracy, score, f1 = [], [], []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        clf = LogisticRegression(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = np.array(clf.predict(X_test))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        score.append(score_function(tp,fp,fn,tn))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(score)\n",
    "\n",
    "def log_reg_param_tune(params, X, y ,n_splits=5):\n",
    "    ps = paramsearch(params)\n",
    "    for prms in chain(ps.grid_search(['C'])):\n",
    "        res = crossvaltest_log_reg(prms,X, y,n_splits)\n",
    "        ps.register_result(res,prms)\n",
    "    return ps.bestparam(), ps.bestscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL_TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cat = {'depth':[1,3,5,7],\n",
    "              'iterations':[100, 200,400,600,800,1000,2000],\n",
    "              'learning_rate':[0.03,0.001,0.01,0.1], \n",
    "              'l2_leaf_reg':[1,5,10,100],\n",
    "              'border_count':[2,5,10,20,50,100],\n",
    "              'thread_count':4,\n",
    "              'silent': True}\n",
    "params_cat, best_cat = cat_param_tune(params_cat,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {'max_depth':[1,3,5,-1],\n",
    "              'boosting': ['gbdt', 'dart', 'goss'],\n",
    "              'num_leaves': [20, 31, 40, 50],\n",
    "              'num_iterations':[100, 200,400,600,800,1000,1500],\n",
    "              'learning_rate':[0.03,0.001,0.01,0.1]}\n",
    "params_lgb, best_lgb = lgb_param_tune(params_lgb,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xg = {'max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "             'n_estimators':[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100],\n",
    "             'learning_rate':[0.03,0.001,0.01,0.1], \n",
    "             'min_child_weight': [1,2,3,4]}\n",
    "params_xg_boost, best_xg = xgboost_param_tune(params_xg,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ada = {'learning_rate':[0.03,0.001,0.01,0.1],\n",
    "              'n_estimators':[100, 300, 500, 700, 900, 1000],\n",
    "              'algorithm': ['SAMME', 'SAMME.R']}\n",
    "params_ada, best_ada = ada_param_tune(params_ada,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log_reg = {'C':[0.001,0.01,0.1,1,10,100,1000]}\n",
    "params_log_reg, best_log_reg = log_reg_param_tune(params_log_reg,X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost best score = 39.00000000002088\n",
      "LightGbm best score = 64.00000000003571\n",
      "XgBoost best score = 51.99999999989377\n",
      "AdaBoost best score = 65.99999999983409\n",
      "LogisticRegression best score = 67.99999999985357\n"
     ]
    }
   ],
   "source": [
    "print('CatBoost best score = {0}'.format(best_cat))\n",
    "print('LightGbm best score = {0}'.format(best_lgb))\n",
    "print('XgBoost best score = {0}'.format(best_xg))\n",
    "print('AdaBoost best score = {0}'.format(best_ada))\n",
    "print('LogisticRegression best score = {0}'.format(best_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting': 'goss',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 1,\n",
       " 'num_iterations': 1500,\n",
       " 'num_leaves': 20}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL_TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score = 65.0\n",
      "Mean Accuracy = 0.9920156028368794\n",
      "Mean F1_score = 0.9233022533022532\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "accuracy, score, f1 = [], [], []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(**params_log_reg)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_log_reg = np.array(clf.predict(X_test))\n",
    "    \n",
    "    clf = XGBClassifier(**params_xg_boost)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_xg = np.array(clf.predict(X_test))\n",
    "    \n",
    "    clf = AdaBoostClassifier(**params_ada)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_ada = np.array(clf.predict(X_test))\n",
    "    \n",
    "    clf = CatBoostClassifier(**params_cat)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_cat = np.array(clf.predict(X_test))\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(**params_lgb)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_lgb = np.array(clf.predict(X_test))\n",
    "    \n",
    "    \n",
    "    y_pred = []\n",
    "    for i in range(len(y_pred_cat)):\n",
    "        temp_prediction = [float(y_pred_log_reg[i]), float(y_pred_xg[i]), float(y_pred_lgb[i]), float(y_pred_ada[i]), float(y_pred_cat[i])]\n",
    "        y_pred.append(most_common(temp_prediction))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    score.append(score_function(tp,fp,fn,tn))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "print('Mean Score = {0}'.format(np.mean(score)))\n",
    "print('Mean Accuracy = {0}'.format(np.mean(accuracy)))\n",
    "print('Mean F1_score = {0}'.format(np.mean(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
